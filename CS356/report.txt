I had some trouble getting viable numbers out of this assignment. I first did a program that did a left-hand Reimann sum that would sum over a time range for a variable range. However, this program would not return anything other than 0 for anything under a range of several thousand, even when the intervals were in .01 increments.For this reason I decided to redo the assignment with the example proposal, which was calculating the digits of pi with a variable number of terms. To do this I implemented a for loop that executed the Fibonacci sequence for finding pi. This was only marginally better. I ran several executions, and found out values that would produce more meaningfull numbers (non-zero). The benchmark tests I ran were (for simplicity's sake) 99,999 , 999,999 , and 9,999,999. The results I got were fairly linear, as I expected they would be since I was unable to test smaller values. The time for 999,999 terms scales to be proportionally .01 lower than the time of 99,999 - making them virtually the same. In addition, the time for 999,999 scales to indicate it should take 1550 ms for 9,999,999, compared to the actual average value of 1460, which is slightly more of a difference, but still not very different considering the number of tests run is relatively small. Due to this lack of precision, I can only speculate about what would happen at lower numbers.I did notice, for example, that at 99,999 iterations I would infrequently get 32 instead of 15 or 16. I hypothesize that this would be more frequent the more processes/applications I had running, because more and more the program would need to wait upon other processes to take their cycles before it could complete execution. In addition, I imagine these number would vary drastically if I had more or less cores (or virtual cores) in my machine.